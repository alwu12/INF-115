{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94d82dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google.generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google.generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google.generativeai)\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google.generativeai)\n",
      "  Downloading google_api_python_client-2.170.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google.generativeai)\n",
      "  Downloading google_auth-2.40.2-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting protobuf (from google.generativeai)\n",
      "  Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting pydantic (from google.generativeai)\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting tqdm (from google.generativeai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions (from google.generativeai)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-core (from google.generativeai)\n",
      "  Downloading google_api_core-2.25.0rc1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from google.generativeai)\n",
      "  Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google.generativeai)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting requests<3.0.0,>=2.18.0 (from google-api-core->google.generativeai)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Downloading grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google.generativeai)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google.generativeai)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google.generativeai)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai)\n",
      "  Downloading charset_normalizer-3.4.2-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai)\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=2.15.0->google.generativeai)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google.generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google.generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google.generativeai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google.generativeai)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic->google.generativeai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic->google.generativeai)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic->google.generativeai)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\alvin\\downloads\\uci cs classes\\inf-115\\assignment5\\inf115-hw5\\hw5\\.venv\\lib\\site-packages (from tqdm->google.generativeai) (0.4.6)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 22.7 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.25.0rc1-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth-2.40.2-py2.py3-none-any.whl (216 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.3/4.3 MB 32.1 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.71.0-py3-none-any.whl (14 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp312-cp312-win_amd64.whl (105 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading google_api_python_client-2.170.0-py3-none-any.whl (13.5 MB)\n",
      "   ---------------------------------------- 0.0/13.5 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 4.7/13.5 MB 22.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.5/13.5 MB 38.5 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 54.6 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: urllib3, uritemplate, typing-extensions, tqdm, pyparsing, pyasn1, protobuf, idna, grpcio, charset-normalizer, certifi, cachetools, annotated-types, typing-inspection, rsa, requests, pydantic-core, pyasn1-modules, proto-plus, httplib2, googleapis-common-protos, pydantic, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google.generativeai\n",
      "\n",
      "   ----------------------------------------  0/29 [urllib3]\n",
      "   ----------------------------------------  0/29 [urllib3]\n",
      "   ---- -----------------------------------  3/29 [tqdm]\n",
      "   ---- -----------------------------------  3/29 [tqdm]\n",
      "   ---- -----------------------------------  3/29 [tqdm]\n",
      "   ----- ----------------------------------  4/29 [pyparsing]\n",
      "   ------ ---------------------------------  5/29 [pyasn1]\n",
      "   ------ ---------------------------------  5/29 [pyasn1]\n",
      "   -------- -------------------------------  6/29 [protobuf]\n",
      "   -------- -------------------------------  6/29 [protobuf]\n",
      "   -------- -------------------------------  6/29 [protobuf]\n",
      "   -------- -------------------------------  6/29 [protobuf]\n",
      "   --------- ------------------------------  7/29 [idna]\n",
      "   ----------- ----------------------------  8/29 [grpcio]\n",
      "   ----------- ----------------------------  8/29 [grpcio]\n",
      "   ----------- ----------------------------  8/29 [grpcio]\n",
      "   ------------ ---------------------------  9/29 [charset-normalizer]\n",
      "   ---------------- ----------------------- 12/29 [annotated-types]\n",
      "   ------------------- -------------------- 14/29 [rsa]\n",
      "   ------------------- -------------------- 14/29 [rsa]\n",
      "   ------------------- -------------------- 14/29 [rsa]\n",
      "   -------------------- ------------------- 15/29 [requests]\n",
      "   ----------------------- ---------------- 17/29 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 17/29 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 17/29 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 17/29 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 17/29 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 17/29 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 17/29 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 17/29 [pyasn1-modules]\n",
      "   ------------------------ --------------- 18/29 [proto-plus]\n",
      "   -------------------------- ------------- 19/29 [httplib2]\n",
      "   --------------------------- ------------ 20/29 [googleapis-common-protos]\n",
      "   --------------------------- ------------ 20/29 [googleapis-common-protos]\n",
      "   --------------------------- ------------ 20/29 [googleapis-common-protos]\n",
      "   --------------------------- ------------ 20/29 [googleapis-common-protos]\n",
      "   --------------------------- ------------ 20/29 [googleapis-common-protos]\n",
      "   --------------------------- ------------ 20/29 [googleapis-common-protos]\n",
      "   ---------------------------- ----------- 21/29 [pydantic]\n",
      "   ---------------------------- ----------- 21/29 [pydantic]\n",
      "   ---------------------------- ----------- 21/29 [pydantic]\n",
      "   ---------------------------- ----------- 21/29 [pydantic]\n",
      "   ---------------------------- ----------- 21/29 [pydantic]\n",
      "   ---------------------------- ----------- 21/29 [pydantic]\n",
      "   ---------------------------- ----------- 21/29 [pydantic]\n",
      "   ------------------------------- -------- 23/29 [google-auth]\n",
      "   ------------------------------- -------- 23/29 [google-auth]\n",
      "   ------------------------------- -------- 23/29 [google-auth]\n",
      "   ------------------------------- -------- 23/29 [google-auth]\n",
      "   ------------------------------- -------- 23/29 [google-auth]\n",
      "   --------------------------------- ------ 24/29 [google-auth-httplib2]\n",
      "   ---------------------------------- ----- 25/29 [google-api-core]\n",
      "   ---------------------------------- ----- 25/29 [google-api-core]\n",
      "   ---------------------------------- ----- 25/29 [google-api-core]\n",
      "   ---------------------------------- ----- 25/29 [google-api-core]\n",
      "   ----------------------------------- ---- 26/29 [google-api-python-client]\n",
      "   ----------------------------------- ---- 26/29 [google-api-python-client]\n",
      "   ----------------------------------- ---- 26/29 [google-api-python-client]\n",
      "   ----------------------------------- ---- 26/29 [google-api-python-client]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   ------------------------------------ -- 27/29 [google-ai-generativelanguage]\n",
      "   -------------------------------------- - 28/29 [google.generativeai]\n",
      "   -------------------------------------- - 28/29 [google.generativeai]\n",
      "   -------------------------------------- - 28/29 [google.generativeai]\n",
      "   -------------------------------------- - 28/29 [google.generativeai]\n",
      "   -------------------------------------- - 28/29 [google.generativeai]\n",
      "   ---------------------------------------- 29/29 [google.generativeai]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 cachetools-5.5.2 certifi-2025.4.26 charset-normalizer-3.4.2 google-ai-generativelanguage-0.6.15 google-api-core-2.25.0rc1 google-api-python-client-2.170.0 google-auth-2.40.2 google-auth-httplib2-0.2.0 google.generativeai-0.8.5 googleapis-common-protos-1.70.0 grpcio-1.71.0 grpcio-status-1.71.0 httplib2-0.22.0 idna-3.10 proto-plus-1.26.1 protobuf-5.29.5 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.5 pydantic-core-2.33.2 pyparsing-3.2.3 requests-2.32.3 rsa-4.9.1 tqdm-4.67.1 typing-extensions-4.13.2 typing-inspection-0.4.1 uritemplate-4.1.1 urllib3-2.4.0\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting filelock (from datasets)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting numpy>=1.17 (from datasets)\n",
      "  Downloading numpy-2.2.6-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-20.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\alvin\\downloads\\uci cs classes\\inf-115\\assignment5\\inf115-hw5\\hw5\\.venv\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\alvin\\downloads\\uci cs classes\\inf-115\\assignment5\\inf115-hw5\\hw5\\.venv\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.32.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\alvin\\downloads\\uci cs classes\\inf-115\\assignment5\\inf115-hw5\\hw5\\.venv\\lib\\site-packages (from datasets) (25.0)\n",
      "Collecting pyyaml>=5.1 (from datasets)\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.12.4-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.6.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.4.4-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.3.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.20.0-cp312-cp312-win_amd64.whl.metadata (74 kB)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\alvin\\downloads\\uci cs classes\\inf-115\\assignment5\\inf115-hw5\\hw5\\.venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\alvin\\downloads\\uci cs classes\\inf-115\\assignment5\\inf115-hw5\\hw5\\.venv\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alvin\\downloads\\uci cs classes\\inf-115\\assignment5\\inf115-hw5\\hw5\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alvin\\downloads\\uci cs classes\\inf-115\\assignment5\\inf115-hw5\\hw5\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alvin\\downloads\\uci cs classes\\inf-115\\assignment5\\inf115-hw5\\hw5\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: colorama in c:\\users\\alvin\\downloads\\uci cs classes\\inf-115\\assignment5\\inf115-hw5\\hw5\\.venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\alvin\\downloads\\uci cs classes\\inf-115\\assignment5\\inf115-hw5\\hw5\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alvin\\downloads\\uci cs classes\\inf-115\\assignment5\\inf115-hw5\\hw5\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading aiohttp-3.12.4-cp312-cp312-win_amd64.whl (440 kB)\n",
      "Downloading multidict-6.4.4-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Downloading yarl-1.20.0-cp312-cp312-win_amd64.whl (92 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.6.0-cp312-cp312-win_amd64.whl (120 kB)\n",
      "Downloading huggingface_hub-0.32.2-py3-none-any.whl (509 kB)\n",
      "Downloading numpy-2.2.6-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 7.9/12.6 MB 48.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 44.0 MB/s eta 0:00:00\n",
      "Downloading propcache-0.3.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Downloading pyarrow-20.0.0-cp312-cp312-win_amd64.whl (25.7 MB)\n",
      "   ---------------------------------------- 0.0/25.7 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 8.4/25.7 MB 43.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 16.5/25.7 MB 40.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.4/25.7 MB 44.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.7/25.7 MB 38.7 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ---------------------------------------  11.3/11.5 MB 54.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 47.8 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, pyyaml, pyarrow, propcache, numpy, multidict, fsspec, frozenlist, filelock, dill, attrs, aiohappyeyeballs, yarl, pandas, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
      "\n",
      "   ----------------------------------------  0/21 [pytz]\n",
      "   ----------------------------------------  0/21 [pytz]\n",
      "   - --------------------------------------  1/21 [xxhash]\n",
      "   --- ------------------------------------  2/21 [tzdata]\n",
      "   --- ------------------------------------  2/21 [tzdata]\n",
      "   ----- ----------------------------------  3/21 [pyyaml]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ----------- ----------------------------  6/21 [numpy]\n",
      "   ------------- --------------------------  7/21 [multidict]\n",
      "   --------------- ------------------------  8/21 [fsspec]\n",
      "   --------------- ------------------------  8/21 [fsspec]\n",
      "   --------------- ------------------------  8/21 [fsspec]\n",
      "   ----------------- ----------------------  9/21 [frozenlist]\n",
      "   -------------------- ------------------- 11/21 [dill]\n",
      "   -------------------- ------------------- 11/21 [dill]\n",
      "   -------------------- ------------------- 11/21 [dill]\n",
      "   ---------------------- ----------------- 12/21 [attrs]\n",
      "   -------------------------- ------------- 14/21 [yarl]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ---------------------------- ----------- 15/21 [pandas]\n",
      "   ------------------------------ --------- 16/21 [multiprocess]\n",
      "   ------------------------------ --------- 16/21 [multiprocess]\n",
      "   ------------------------------ --------- 16/21 [multiprocess]\n",
      "   -------------------------------- ------- 17/21 [huggingface-hub]\n",
      "   -------------------------------- ------- 17/21 [huggingface-hub]\n",
      "   -------------------------------- ------- 17/21 [huggingface-hub]\n",
      "   -------------------------------- ------- 17/21 [huggingface-hub]\n",
      "   -------------------------------- ------- 17/21 [huggingface-hub]\n",
      "   -------------------------------- ------- 17/21 [huggingface-hub]\n",
      "   -------------------------------- ------- 17/21 [huggingface-hub]\n",
      "   -------------------------------- ------- 17/21 [huggingface-hub]\n",
      "   -------------------------------- ------- 17/21 [huggingface-hub]\n",
      "   ------------------------------------ --- 19/21 [aiohttp]\n",
      "   ------------------------------------ --- 19/21 [aiohttp]\n",
      "   ------------------------------------ --- 19/21 [aiohttp]\n",
      "   ------------------------------------ --- 19/21 [aiohttp]\n",
      "   -------------------------------------- - 20/21 [datasets]\n",
      "   -------------------------------------- - 20/21 [datasets]\n",
      "   -------------------------------------- - 20/21 [datasets]\n",
      "   -------------------------------------- - 20/21 [datasets]\n",
      "   -------------------------------------- - 20/21 [datasets]\n",
      "   -------------------------------------- - 20/21 [datasets]\n",
      "   -------------------------------------- - 20/21 [datasets]\n",
      "   -------------------------------------- - 20/21 [datasets]\n",
      "   ---------------------------------------- 21/21 [datasets]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.4 aiosignal-1.3.2 attrs-25.3.0 datasets-3.6.0 dill-0.3.8 filelock-3.18.0 frozenlist-1.6.0 fsspec-2025.3.0 huggingface-hub-0.32.2 multidict-6.4.4 multiprocess-0.70.16 numpy-2.2.6 pandas-2.2.3 propcache-0.3.1 pyarrow-20.0.0 pytz-2025.2 pyyaml-6.0.2 tzdata-2025.2 xxhash-3.5.0 yarl-1.20.0\n"
     ]
    }
   ],
   "source": [
    "# Required packages to download, you only need to run this once!\n",
    "!pip3 install google.generativeai\n",
    "!pip3 install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:37:11.867776Z",
     "start_time": "2025-04-01T19:37:10.877607Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import re\n",
    "import time\n",
    "\n",
    "# TODO: put your Google API key\n",
    "api_key = 'AIzaSyBK375J_WOHHnxjTY8_PnN2rUIj48KoBjY'  # TODO put your api key\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel(model_name='gemini-1.5-flash')\n",
    "\n",
    "def call_google_api(prompt, my_model):\n",
    "    \"\"\"\n",
    "    Method for getting a response from the Gemini API.\n",
    "    Args:\n",
    "        - prompt (str): The input instruction for the language model.\n",
    "        - my_model: The Gemini model instance.\n",
    "    Returns:\n",
    "        str: The generated response, or None if no response is available.\n",
    "    \"\"\"\n",
    "    google_model_config = genai.types.GenerationConfig(temperature=0, max_output_tokens=6000)\n",
    "    completion = my_model.generate_content(prompt, generation_config=google_model_config)\n",
    "    try:\n",
    "        gemini_response_text = completion.text\n",
    "    except Exception as e:\n",
    "        print(\"Gemini response error: \" + str(e))\n",
    "        try:\n",
    "            if hasattr(completion.parts, 'text'):\n",
    "                gemini_response_text = completion.parts.text\n",
    "            else:\n",
    "                gemini_response_text = None\n",
    "        except Exception:\n",
    "            gemini_response_text = None\n",
    "    return gemini_response_text\n",
    "\n",
    "def clean_generated_code(generated_code, language):\n",
    "    \"\"\"\n",
    "    Helper method for cleaning LLM-generated code.\n",
    "    Args:\n",
    "        - generated_code (str): The raw code output from the LLM.\n",
    "        - language (str): A string indicating the language of the code (e.g., \"python3\").\n",
    "    Returns:\n",
    "        str: Cleaned LLM-generated code.\n",
    "    \"\"\"\n",
    "    if not generated_code:\n",
    "        return \"\"\n",
    "    \n",
    "    code = re.sub(r\"(def[^\\n]+:\\s*)('''[\\s\\S]*?''')\", r\"\\1\", generated_code)\n",
    "    code = re.sub(r'(def[^\\n]+:\\s*)(\"\"\"[\\s\\S]*?\"\"\")', r\"\\1\", code)\n",
    "    code = re.sub(r\"(def[^\\n]+:\\n)\\s*\\n\", r\"\\1\", code)\n",
    "    \n",
    "    cleaned_code = []\n",
    "    for line in code.split('\\n'):\n",
    "        if f\"```{language}\" in line or line.strip().startswith(\"```\"):\n",
    "            continue\n",
    "        cleaned_code.append(line)\n",
    "    return \"\\n\".join(cleaned_code)\n",
    "\n",
    "def get_llm_response(prompt):\n",
    "    \"\"\"\n",
    "    Wrapper method for retrieving and cleaning LLM-generated code using the two functions above.\n",
    "    1. call_google_api: Gets a response from the Gemini 1.5 model via the Google API.\n",
    "    2. clean_generated_code: Cleans the generated code by removing code block markers.\n",
    "    Args:\n",
    "        - prompt (str): The code generation prompt.\n",
    "\n",
    "    Returns:\n",
    "        str: Cleaned code if successful, otherwise None.\n",
    "    \"\"\"\n",
    "    # Maximum 5 attempts (this number can be adjusted as needed).\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            res = call_google_api(prompt, model)\n",
    "            return clean_generated_code(res, 'python3')\n",
    "        except Exception as e:\n",
    "            time.sleep(5)\n",
    "        if res is None or res.lower() == 'none':\n",
    "            print(f\"llm did not respond for problem\")\n",
    "    return None\n",
    "\n",
    "# Do NOT change this prompt template\n",
    "CODE_GENERATION_PROMPT_TEMPLATE = \"\"\"\n",
    "System:\n",
    "## Persona\n",
    "- You are a code generation assistant who specializes in {language}.\n",
    "- You follow strict guidelines for producing high-quality, readable, and correct code.\n",
    "\n",
    "## Instructions\n",
    "- You will be given a coding question specification, which consists of function signatures, and docstrings.\n",
    "- Your task is to **generate the complete, correct {language} code** based on the provided docstring and requirements.\n",
    "- You must think step by step when generating the {language} code.\n",
    "\n",
    "## Output Format\n",
    "- Your **final code** should be enclosed in a code block, for example:\n",
    "  ```{language}\n",
    "  # your code here\n",
    "- Do not add additional text or commentary outside of the code block.\n",
    "\n",
    "User:\n",
    "### Coding Question Specification\n",
    "{problem_stmt}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c9ec4f9b9449590",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:37:15.567180Z",
     "start_time": "2025-04-01T19:37:15.564668Z"
    }
   },
   "outputs": [],
   "source": [
    "# Keep the function name as: check_if_last_char_is_a_letter\n",
    "\n",
    "original_stmt = \"\"\"def check_if_last_char_is_a_letter(txt):\n",
    "    '''\n",
    "    Create a function that returns True if the last character\n",
    "    of a given string is an alphabetical character and is not\n",
    "    a part of a word, and False otherwise.\n",
    "    Note: \"word\" is a group of characters separated by space.\n",
    "\n",
    "    Examples:\n",
    "    check_if_last_char_is_a_letter(\"apple pi e\") ➞ True\n",
    "    check_if_last_char_is_a_letter(\"\") ➞ False \n",
    "    '''\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d0ae1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def check_if_last_char_is_a_letter(txt):\n",
      "    if not txt:\n",
      "        return False\n",
      "    \n",
      "    txt = txt.strip()\n",
      "    if not txt:\n",
      "        return False\n",
      "\n",
      "    last_char = txt[-1]\n",
      "    \n",
      "    if 'a' <= last_char <= 'z' or 'A' <= last_char <= 'Z':\n",
      "        words = txt.split()\n",
      "        if last_char == words[-1][-1]:\n",
      "            return True\n",
      "        else:\n",
      "            return False\n",
      "    else:\n",
      "        return False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Generate code using the Gemini model. Here we build the prompt using the `original_stmt`\"\"\"\n",
    "\n",
    "# Specify the function name and Canvas group number\n",
    "function_name = 'check_if_last_char_is_a_letter'\n",
    "canvas_group_number = '83'       #TODO:you can change this to your Canvas group name\n",
    "\n",
    "# LLM-generated code using original_stmt\n",
    "my_prompt = CODE_GENERATION_PROMPT_TEMPLATE.format(problem_stmt=original_stmt, language=\"python3\")\n",
    "llm_code_original = get_llm_response(my_prompt)\n",
    "print(llm_code_original)\n",
    "\n",
    "# Save the Python file for testing\n",
    "filename_original = f\"hw5-{function_name}-group{canvas_group_number}-original.py\"\n",
    "with open(filename_original, \"w\") as file:\n",
    "    file.write(llm_code_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19328da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 failed: input=apple, expected=False, got=True\n",
      "Test case 2 passed.\n",
      "Test case 3 passed.\n",
      "Test case 4 passed.\n",
      "Test 5 failed: input=ends with space , expected=False, got=True\n",
      "Test case 6 passed.\n",
      "Test case 7 passed.\n",
      "Test case 8 passed.\n",
      "Test case 9 passed.\n",
      "Test case 10 passed.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import importlib.util\n",
    "\n",
    "# Load the JSON file for the test cases\n",
    "with open(f'test_case_{function_name}.json', 'r') as f:\n",
    "    test_cases = json.load(f)[\"test_case\"]\n",
    "\n",
    "# Load the saved Python file using function name and file_name\n",
    "spec = importlib.util.spec_from_file_location(function_name, filename_improved)\n",
    "module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(module)\n",
    "function = getattr(module, function_name)\n",
    "\n",
    "# Run test cases\n",
    "for idx, case in enumerate(test_cases):\n",
    "    try:\n",
    "        inputs = case[\"input\"]\n",
    "        if isinstance(inputs, (list, tuple)):\n",
    "            try:\n",
    "                result = function(*inputs)\n",
    "            except TypeError:\n",
    "                result = function(inputs)\n",
    "        else:\n",
    "            result = function(inputs)\n",
    "\n",
    "        assert result == case[\"expected\"], f\"Test {idx+1} failed: input={inputs}, expected={case['expected']}, got={result}\"\n",
    "        print(f\"Test case {idx+1} passed.\")\n",
    "    except AssertionError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b2b5b6fc3ce263",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:37:29.655218Z",
     "start_time": "2025-04-01T19:37:29.652631Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 1. Generate code using `original_stmt`.\n",
    "# 2. Write test cases (in the provided JSON file) to evaluate the LLM-generated code based on `original_stmt`.\n",
    "# 3. Run your test cases and demonstrate examples of both failing and passing cases.\n",
    "#    (You do not have to follow the exact implementation shown in the demo_same_chars file, but you are welcome to reference or reuse parts of it.)\n",
    "# 4. Write a `new_stmt` that improves the prompt to enhance the accuracy of LLM-generated code.\n",
    "# 5. Generate code using `new_stmt` and run your test cases, ensuring that the code passes all of them.\n",
    "# 6. Ensure you write as many test cases as needed to cover all edge cases.\n",
    "#    We will run the autograder against your final LLM-generated code (using `new_stmt`), ensure that it can pass all autograder test cases.\n",
    "\n",
    "new_stmt = \"\"\"def check_if_last_char_is_a_letter(txt):\n",
    "    '''\n",
    "    Create a function that returns True if the last character\n",
    "    of a given string is an alphabetical character and is not\n",
    "    a part of a word, and False otherwise. The input may be multiple words or a single word of varying lengths.\n",
    "    Check the last letter of the last word, and if it is a single alphabetical letter then return true.\n",
    "    Note: \"word\" is a group of characters separated by space.\n",
    "\n",
    "    Examples:\n",
    "    check_if_last_char_is_a_letter(\"apple\") ➞ False\n",
    "    check_if_last_char_is_a_letter(\"\") ➞ False \n",
    "    check_if_last_char_is_a_letter(\"apple pi e\") ➞ True\n",
    "    check_if_last_char_is_a_letter(\"hello1\") ➞ False\n",
    "    check_if_last_char_is_a_letter(\"1234!\") ➞ False\n",
    "    check_if_last_char_is_a_letter(\"ends with space \") ➞ False\n",
    "    check_if_last_char_is_a_letter(\"a\") ➞ True\n",
    "    check_if_last_char_is_a_letter(\"Z\") ➞ True\n",
    "    check_if_last_char_is_a_letter(\"\") ➞ False\n",
    "    check_if_last_char_is_a_letter(\"abc123\") ➞ False\n",
    "    check_if_last_char_is_a_letter(\"lastCharIsLetterA\") ➞ False\n",
    "    '''\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d2a30c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def check_if_last_char_is_a_letter(txt):\n",
      "    if not txt:\n",
      "        return False\n",
      "    words = txt.split()\n",
      "    if not words:\n",
      "        return False\n",
      "    last_word = words[-1]\n",
      "    if not last_word:\n",
      "        return False\n",
      "    last_char = last_word[-1]\n",
      "    if 'a' <= last_char <= 'z' or 'A' <= last_char <= 'Z':\n",
      "        if len(last_word) == 1:\n",
      "            return True\n",
      "        else:\n",
      "            return False\n",
      "    else:\n",
      "        return False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Generate code using the Gemini model. Here we build the prompt using the `original_stmt`\"\"\"\n",
    "\n",
    "# Specify the function name and Canvas group number\n",
    "function_name = 'check_if_last_char_is_a_letter'\n",
    "canvas_group_number = '83'       #TODO:you can change this to your Canvas group name\n",
    "\n",
    "# LLM-generated code using original_stmt\n",
    "my_prompt = CODE_GENERATION_PROMPT_TEMPLATE.format(problem_stmt=new_stmt, language=\"python3\")\n",
    "llm_code_improved = get_llm_response(my_prompt)\n",
    "print(llm_code_improved)\n",
    "\n",
    "# Save the Python file for testing\n",
    "filename_improved = f\"hw5-{function_name}-group{canvas_group_number}-improved.py\"\n",
    "with open(filename_improved, \"w\") as file:\n",
    "    file.write(llm_code_improved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8b7ffd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case 1 passed.\n",
      "Test case 2 passed.\n",
      "Test case 3 passed.\n",
      "Test case 4 passed.\n",
      "Test case 5 passed.\n",
      "Test case 6 passed.\n",
      "Test case 7 passed.\n",
      "Test case 8 passed.\n",
      "Test case 9 passed.\n",
      "Test case 10 passed.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import importlib.util\n",
    "\n",
    "# Load the JSON file for the test cases\n",
    "with open(f'test_case_{function_name}.json', 'r') as f:\n",
    "    test_cases = json.load(f)[\"test_case\"]\n",
    "\n",
    "# Load the saved Python file using function name and file_name\n",
    "spec = importlib.util.spec_from_file_location(function_name, filename_improved)\n",
    "module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(module)\n",
    "function = getattr(module, function_name)\n",
    "\n",
    "# Run test cases\n",
    "for idx, case in enumerate(test_cases):\n",
    "    try:\n",
    "        inputs = case[\"input\"]\n",
    "        if isinstance(inputs, (list, tuple)):\n",
    "            try:\n",
    "                result = function(*inputs)\n",
    "            except TypeError:\n",
    "                result = function(inputs)\n",
    "        else:\n",
    "            result = function(inputs)\n",
    "\n",
    "        assert result == case[\"expected\"], f\"Test {idx+1} failed: input={inputs}, expected={case['expected']}, got={result}\"\n",
    "        print(f\"Test case {idx+1} passed.\")\n",
    "    except AssertionError as e:\n",
    "        print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
